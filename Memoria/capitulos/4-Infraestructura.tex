\chapter{Infraestructura desarrollada}\label{cap.infraestructura}

El propósito de este proyecto es que un coche autónomo sea capaz de conducir en diferentes circuitos mediante distintas redes neuronales que aprenden control visual. El coche dispondrá de una cámara que le proporciona información de su entorno, permiténdole tomar decisiones.\\

El vehículo, como hemos mencionado, debe ser capaz de aprender determinadas acciones. Para que el coche pueda aprender es necesario disponer de una serie de datos, por lo que se ha creado un conjunto de entrenamiento que se describirá en la Sección \ref{dataset}. Con el fin de generar este conjunto de datos se ha programado un piloto autónomo basado en visión (Sección \ref{piloto}) que es capaz de dar vueltas alrededor del circuito sin intervención humana.\\

Además se definirán los circuitos de carreras empleados tanto para el entrenamiento de las redes como para el \textit{test}. 

\section{Circuitos de carreras en Gazebo}\label{modelos_circuitos}

El objetivo de este proyecto es que un Fórmula 1 sea capaz de conducir de forma autónoma por un circuito de carreras, por lo que tendremos que crear diferentes entornos (circuitos) donde se moverá. Para facilitar el algoritmo del piloto autónomo programado y del piloto autónomo basado en redes neuronales, los circuitos tienen una línea roja pintada en el suelo.\\

Los modelos de circuitos fueron creados con una herrramienta de modelado 3D (Blender, SketchUp, etc). La mayoría de los circuitos son de grandes dimensiones. En estos circuitos no veremos muchas gradas alrededor, ni público ni otros elementos habituales de los circuitos reales, sino que se ha simplificado para que sea rápida la ejecución del simulador. Los mundos que tienen muchos detalles son más costosos computacionalmente de simular. Lo que podremos ver en estos circuitos son elementos propios de carreteras como rectas, curvas simples o pronunciadas, una línea de salida, paredes que evitan que el coche se salga del recorrido, y en algunos casos una grada y césped de adorno.\\

El primer modelo de circuito empleado se llama \textit{pistaSimple}. Es un circuito de carreras de gran tamaño, que consta de una carretera con una línea roja en el suelo, una línea de salida, y las paredes para evitar que el coche se salga del circuito. Este modelo se puede observar en la Figura \ref{fig.simple}.\\

\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/circuit_Simple.png}
		\caption{Modelo pistaSimple}
		\label{fig.simple}
		\end{center}
\end{figure}

El segundo modelo de circuito se denomina \textit{monacoLine} y simula el circuito de carreras de Mónaco, también conocido como Montecarlo. Este modelo consta del circuito en sí mismo, así como línea de salida, paredes que rodean el circuito, césped de adorno, y una grada pequeña. El modelo \textit{monacoLine} se puede ver en la Figura \ref{fig.monaco}.\\


\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/circuit_Monaco.png}
		\caption{Modelo monacoLine}
		\label{fig.monaco}
		\end{center}
\end{figure}

El tercer modelo simula el circuito de carretas Nürburgring (Alemania) acortado, llamado \textit{nurburgrinLine}. Se ha modelado el circuito con una línea de salida, la carretera, paredes para evitar que el robot se salga del recorrido, una grada pequeña y césped de adorno. Este modelo se puede observar en la Figura \ref{fig.nurburgrin}.\\

\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/circuit_Nurburgrin.png}
		\caption{Modelo nurburgrinLine}
		\label{fig.nurburgrin}
		\end{center}
\end{figure}

El cuarto modelo de circuito, llamado \textit{curveGP}, simula un circuito que no tiene ninguna recta, solamente tiene curvas, tanto curvas leves como abruptas. Este circuito es de gran tamaño, y no tiene ningún elemento de adorno. Se puede ver en la Figura \ref{fig.curveGP}.\\

El quinto modelo de circuito se denomina \textit{pista\_simple}. Este circuito es el más corto de todos, no tiene ningún elemento de adorno. Se puede ver en la Figura \ref{fig.small}.\\


\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/circuit_CurveGP.png}
		\caption{Modelo curveGP}
		\label{fig.curveGP}
		\end{center}
\end{figure}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/circuit_Small.png}
		\caption{Modelo pista\_simple}
		\label{fig.small}
		\end{center}
\end{figure}


Los mundos que se simulan con Gazebo son mundos 3D. Estos mundos se cargan en ficheros con extensión .world, que no son más que ficheros \acrshort{xml} definidos en el lenguaje \acrshort{sdf}. Este lenguaje contiene una descripción completa de todos los elementos que tiene el mundo y los robots.\\

Se ha creado un mundo en Gazebo para cada circuito, compuesto por uno de los cinco modelos de circuito y el modelo del coche (\textit{f1ROS}). Los archivos del mundo de cada circuito son iguales en todos los casos, las únicas diferencias son que el nombre del modelo de circuito cambia, y la posición del modelo del coche también, ya que en cada circuito la línea de salida está en un lugar diferente. Por ejemplo, el archivo f1-simple-circuit.world (mundo del circuito \textit{pistaSimple}) tiene el
siguiente aspecto:

\vspace{20pt}
\begin{lstlisting}[frame=single]
<?xml version="1.0" ?>
<sdf version="1.5">
  <world name="default">
    <scene>
      <grid>false</grid>
    </scene>
    <!-- A global light source -->
    <include>
      <uri>model://sun</uri>
    </include>
    <include>
      <uri>model://pistaSimple</uri>
	<pose>-160 17 0 0 0 0</pose>
    </include>
    <include>
      <uri>model://f1ROS</uri>
      <pose>1 0 0 0 0 -1.57</pose>
    </include>

 <scene>
        <sky>
            <clouds>
                <speed>12</speed>
            </clouds>
        </sky>
     </scene>
  <light name='user_directional_light_0' type='directional'>
      <pose frame=''>0 0 10 0 -0 0</pose>
      <diffuse>0.8 0.8 0.8 1</diffuse>
      <specular>0.2 0.2 0.2 1</specular>
      <direction>0.1 0.1 -0.9</direction>
      <attenuation>
        <range>1000</range>
        <constant>0.9</constant>
        <linear>0.01</linear>
        <quadratic>0.001</quadratic>
      </attenuation>
      <cast_shadows>1</cast_shadows>
  </light>

  </world>
</sdf>

\end{lstlisting}

Además de este fichero de configuración, es necesario crear un archivo con extensión .launch, que arranca los \textit{plugins} y \textit{drivers} de ROS-Kinetic. En este fichero es necesario indicar a Gazebo algunos argumentos como el nombre del fichero de configuración con el escenario (archivo del mundo), la posibilidad de lanzar una \acrshort{gui}, y algunas opciones de depuración. Es necesario crear un archivo .launch por cada modelo de circuito o escenario. Todos estos archivos serán iguales, excepto que en el argumento ``world\_name'' se modificará el valor del archivo .world empleado. Por ejemplo, para emplear el archivo de configuración \textit{f1-simple-circuit.world}, se ha creado el archivo \textit{f1.launch} que se puede ver a continuación:\\

\vspace{20pt}
\begin{lstlisting}[frame=single]
<?xml version="1.0" encoding="UTF-8"?>
<launch>
  <!-- We resume the logic in empty_world.launch, changing only the name 
  of the world to be launched -->
  <include file="$(find gazebo_ros)/launch/empty_world.launch">
    <arg name="world_name" value="f1-simple-circuit.world"/> <!-- Note: the 
    world_name is with respect to GAZEBO_RESOURCE_PATH environmental
    variable -->
    <arg name="paused" value="false"/>
    <arg name="use_sim_time" value="true"/>
    <arg name="gui" value="true"/>
    <arg name="headless" value="false"/>
    <arg name="debug" value="false"/>
    <arg name="verbose" default="false"/>
  </include>  
</launch>
\end{lstlisting}

Los modelos de circuitos \textit{pistaSimple}, \textit{monacoLine}, \textit{nurburgrinLine} son empleados para el entrenamiento y el \textit{test} de las redes neuronales de extremo a extremo. En los modelos con dependencias temporales (como \acrshort{lstm}) se añade el modelo \textit{curveGP} tanto para entrenamiento como para \textit{test}. Este modelo es empleado para adquirir más datos de curvas, ya que en los anteriores circuitos teníamos muchos más datos de rectas que de curvas, y es necesario que las redes posean más datos de este tipo para que sean capaces de aprender ciertos comportamientos. El modelo \textit{pista\_simple} se emplea únicamente para \textit{test}.\\



\section{Piloto autónomo programado}\label{piloto}

Para entrenar las redes neuronales es necesario disponer de una serie de datos supervisados de conducción autónoma. Con el fin de grabar este conjunto de datos se ha programado un piloto autónomo basado en visión que es capaz de dar vueltas alrededor del circuito de forma autónoma y generar ese conjunto de datos supervisados. \\

El piloto autónomo creado es capaz de navegar rápidamente por un circuito de Fórmula 1 siguiendo una línea roja pintada en el suelo. Para ello, el coche dispone de una cámara en la parte frontal izquierda y unos motores a los que se envían órdenes de velocidad (velocidad de tracción y velocidad de rotación).\\

El coche programado tendrá una parte perceptiva y una parte de control. En la parte perceptiva el vehículo extrae la información relevante de las imágenes: dónde está la línea roja, si está en una recta o en una curva, si ha perdido la línea roja, etc. En la parte de control, el coche implementa un control reactivo PD, que es capaz de corregir la velocidad de giro para mantener al coche por encima de la línea.\\ 


Lo primero que hace el piloto es acceder a las imágenes de la cámara. Es conveniente detectar la línea roja que está en el centro de la carretera, es decir, será necesario realizar una umbralización de esta línea. Para ello, primero transformamos las imágenes al espacio de color HSV, ya que HSV es más robusto que RGB ante cambios de iluminación. Después, se ha realizado una umbralización de la imagen empleando la función \textit{cv2.inRange} de OpenCV. Este filtrado se hace en función al rango de valores de rojo de la línea de la carretera.\\

Si mostramos la imagen tras el filtrado vemos que aparecen puntos en negro que pertenecen a la línea roja y no debería ser así. Esto ocurre en la línea de salida del circuito, ya que se puede ver que la línea parpadea y por lo tanto no tiene siempre el tono de rojo habitual. Este problema lo podemos ver en la Figura \ref{fig.color}. Para solventar este problema se ha aplicado un cierre morfológico (primero hace una dilatación y después una erosión). Esta operación hace que los píxeles que aparecían en negro en la línea filtrada ahora pertenezcan a la línea filtrada, es decir, que aparezcan en blanco. Se puede observar en la Figura \ref{fig.cierre} cómo después de aplicar el cierre morfológico no quedan huecos en la parte segmentada al filtrar la línea roja.\\

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/filtro_color.png}
		\caption{Filtrado de color}
		\label{fig.color}
		\end{center}
\end{figure}


\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/Infraestructura/filtro_cierre.png}
		\caption{Filtrado de color con cierre}
		\label{fig.cierre}
		\end{center}
\end{figure}

Tras obtener una imagen con la línea roja en blanco, se ha tenido en cuenta que si el coche circula sobre la carretera correctamente la línea debería aparecer más o menos centrada en la imagen. Si por el contrario, la línea aparece en la parte izquierda o derecha de la imagen, el coche debería girar puesto que está un poco desviado de la línea roja. De esta forma se puede conocer el giro que debe realizar el coche.\\

Con el fin de analizar la información proporcionada por el filtrado de la imagen es necesario analizar alguna fila de la imagen filtrada. En el caso de que solamente analicemos una única fila de la imagen, no obtendremos suficiente información para saber si nos encontramos en recta o en curva. Por este motivo, se han analizado tres filas de la imagen con el fin de saber si el coche está situado encima de una recta o una curva, o si por otro caso se ha salido el coche de la línea. En nuestro caso analizamos las filas situadas en las posiciones y1 = 260, y2 = 310, e y3 = 350. En estas líneas se calcula el centro de la línea roja, para lo cual se comprueban los valores de la imagen filtrada. Con estos centros (centro de cada fila) podremos saber si nos encontramos en recta o curva.\\

El siguiente paso es procesar esta información. El centro de la línea roja situado en la fila y1 (260) será el único que no perderemos siempre que nos encontremos cerca de la línea roja, ya que es la posición que está situada más arriba. Los centros de la línea roja situados en las filas y2 (310) e y3 (350) es posible que se pierdan al llegar a una curva grande. Si no encontramos la línea roja en la posición y1 es debido a que nos hemos salido de la línea roja. En esta situación el coche deberá ir hacia atrás y girar hacia el centro para continuar su recorrido. Si la última vez que se ha visto la línea estaba a la izquierda de la imagen, quiere decir que el coche se ha salido hacia la derecha, y por tanto tendrá que girar a la izquierda y viceversa. \\

La desviación o error que tenemos en cada instante se calcula respecto a la posición ideal. Esta posición ideal o de referencia puede no ser el centro de la imagen, ya que la cámara no está centrada en el vehículo y mirando exactamente la recta. En este caso, hay que analizar las imágenes cuando el coche está en recta y ver cuál es el centro de referencia (posición ideal). Haciendo algunas pruebas se ha determinado que la posición ideal es x = 326. Las desviaciones se calcularán respecto a este valor objetivo. En nuestro caso calculamos la diferencia entre la posición x de y1 (260) y la posición ideal. Esta es la desviación que tendremos en cuenta a la hora de hacer los diferentes controles PD que se llevan a cabo. Además, se tiene en cuenta un caso por si el coche se ha salido del circuito.\\

Otro de los casos que se han tenido en cuenta en el piloto es si el centro situado en la fila situada más abajo (y3 = 350) se ha perdido. Esto puede ocurrir si estamos en una curva grande. Si se da este caso se realizará un control PD adaptado a esta excepción. En función de la desviación que hay entre el centro situado en la fila de arriba (y1) y el centro situado en la fila de en medio (y2), se darán diferentes situaciones en las que se ajustará un PD diferente.\\

En el piloto programado se ha decidido emplear un control PD, ya que puede ser que el uso de un control P no sea suficiente, puesto que el coche puede oscilar sobre la línea roja. Por lo tanto, es mejor emplear un control PD para evitar estos vaivenes del coche. El control PD (definido por un control derivativo y un control proporcional) sigue la siguiente fórmula:\\

\vspace{10pt}
\begin{lstlisting}
Correccion = kp error + kd (error - errorAnterior)
\end{lstlisting}
\vspace{20pt}

Los valores de las constantes kp y kd se han ajustado experimentalmente. En función de la desviación obtenida se tienen diferentes controladores PD para controlar la velocidad de rotación, y se mantienen diferentes velocidades constantes en función de cada caso para la velocidad de tracción.\\

Otro caso que evaluaremos es si nos situamos en recta o curva. Si estamos en recta se aplicarán unas constantes de control PD y si estamos en curva otras. Para diferenciar si nos encontramos en recta o en curva se empleará la diferencia entre la posición x de y3 (350) y de y1 (260). Lo que se hace exactamente es calcular la recta que pasa por el centro de y1 e y3, y después se mira la posición de x que se encuentra en esta recta para la fila y2 (310). De este modo conociendo el centro de la fila y2 y el punto x que se encuentra en la recta calculada, podemos saber si estamos en curva o recta. \\


El piloto programado es eficaz y consigue completar el recorrido en todos los circuitos creados. Se ha ejecutado en los diferentes circuitos, tanto en sentido horario como en sentido anti-horario. Se han medido los tiempos de simulación que tarda el vehículo en dar una vuelta al circuito en ambos sentidos. En la tabla \ref{tabla_piloto} se muestran los resultados de este piloto.\\


\begin{table}[]
\centering
\caption{Resultados del Pilotaje autónomo explícito}
\label{tabla_piloto}
\begin{tabular}{| c| c |}
\hline
Circuitos & Tiempo simulado \\
\hline \hline
pistaSimple (horario) & 1min 35 seg \\ \hline
pistaSimple (anti-horario) & 1min 33 seg \\ \hline
monacoLine (horario) & 1min 15 seg \\ \hline
monacoLine (anti-horario) & 1min 15 seg \\ \hline
nurburgrinLine (horario) & 1min 02 seg \\ \hline
nurburgrinLine (anti-horario) & 1min 02 seg \\ \hline
curveGP (horario) & 2min 13 seg \\ \hline
curveGP (anti-horario) & 2min 09 seg \\ \hline
pista\_simple (horario) & 1min 00 seg \\ \hline
pista\_simple (anti-horario) & 59 seg \\ \hline
\end{tabular}
\end{table}


\section{Creación de conjunto de datos para entrenamiento neuronal}\label{dataset}

Para que las redes neuronales sean capaces de aprender es necesario crear un conjunto de datos. Como se menciona en el libro ``Deep Learning, Introducción práctica con Keras'' \cite{Jordi_torres}, el conjunto de datos se debe dividir para poder configurar y evaluar el modelo de forma correcta. En \textit{Deep Learning} estos datos se dividen en tres conjuntos: datos de entrenamiento (\textit{training}), datos de validación (\textit{validation}) y datos de prueba (\textit{test}).\\

Los datos de entrenamiento son aquellos que se utilizan para que la red obtenga los parámetros del modelo. Cuando entrenamos un modelo con un conjunto de entrada lo que ocurre es que hacemos que el modelo sea capaz de aprender de forma general un concepto. De esta forma cuando le consultamos por nuevos datos el modelo será capaz de comprender estos nuevos datos y devolver un resultado fiable en función de su capacidad de generalización. Sin embargo, si este modelo no es capaz de adaptarse a los datos de entrada (por ejemplo se produce \textit{underfitting} u \textit{overfitting}), en este caso modificaremos los hiperparámetros del modelo, y después de entrenar el modelo de nuevo con los datos de entrenamiento evaluaremos el modelo con los datos de validación.\\

Los hiperparámetros se pueden ir ajustando guiados por los datos de validación hasta obtener unos resultados de validación que consideremos apropiados. Si hemos seguido este método, lo que ha sucedido es que el modelo se ha ajustado también a los datos de validación. Por este motivo, es necesario reservar un conjunto de \textit{test} que solamente emplearemos al evaluar el modelo cuando consideremos que ya hemos terminado de ajustar los hiperparámetros.\\

Ha sido necesario crear una conjunto de datos para conducción autónoma en el simulador Gazebo. Esta base de datos se ha creado a partir del piloto autónomo programado que se ha explicado en la Sección \ref{piloto}. El conjunto de datos creado es un \textit{dataset} ``casero'' donde se han almacenado las imágenes de la cámara en cada instante, así como los datos de velocidad generados por el piloto programado. Los datos de velocidades se han guardado en un archivo \textit{.json}. En este fichero se han guardado diferentes datos adicionales relacionados con la velocidad. Por un lado, se han almacenado en un diccionario los datos númericos de v y w con las claves \textit{v} y \textit{w}. Por otro lado se han almacenado datos que servirán para entrenar las redes de clasificación. Para almacenar estos datos se han creado diferentes claves con sus valores en función de diferentes clasificaciones. Se han creado diferentes clasificaciones para ver el efecto que tienen en las redes neuronales. A continuación, se puede observar cómo se almacenan los datos de velocidad correspondientes a la primera imagen del \textit{dataset}:\\

\begin{lstlisting}
{"class_v_5": very_fast, "class_w_9": slight, 
"class3": "very_fast", "class2": "slight", 
"classification": "left", "w": 0.029500000000000002, "v": 13}
\end{lstlisting}
\vspace{20pt}

En este ejemplo, se puede observar que hay diferentes claves con su valor como habíamos mencionado. Las claves correspondientes a las diferentes clasificaciones son:

\begin{itemize}
    \item \textit{classification}: Esta clasificación divide los datos entre las clases ``left'' y ``right'' en función de los datos de velocidad de giro. Si la velocidad de giro es negativa el dato se corresponde con la clase ``right'', y si por el contrario es positiva se corresponde con la clase ``left''.
    
    \item \textit{class2}: Esta clasificación divide los datos de la velocidad lineal en 4 clases. Estas clases son: ``slow'' si la velocidad es menor o igual que 7; ``moderate'' si la velocidad es mayor que 7 y menor o igual que 9; ``fast'' si la velocidad es mayor que 9 y menor o igual que 11; y ``very\_fast'' si la velocidad es mayor que 11.
    
    \item \textit{class3}: En esta clasificación se dividen los datos de velocidad angular en 7 clases. Las clases son: ``radically\_left'' si la velocidad de rotación (w) es mayor o igual a 1; ``moderately\_left'' si w es menor que 1 y mayor o igual que 0.5; ``slightly\_left'' si w es menor que 0.5 y mayor o igual que 0.1; ``slight'' si w es menor que 0.1 y mayor a -0.1; ``slightly\_right'' si w es menor o igual que -0.1 y mayor que -0.5; ``moderately\_right''  si w es menor o igual que -0.5 y mayor que -1; y ``radically\_right'' si la velocidad de rotación es menor que -1.
    
    \item \textit{class\_v\_5}: Se dividen los datos de la velocidad lineal (v) en 5 clases. Estas clases son: ``negative'' si v es menor que 0, ``slow'' si la velocidad es menor o igual que 7 y mayor que 0; ``moderate'' si la v es mayor que 7 y menor o igual que 9; ``fast'' si la v es mayor que 9 y menor o igual que 11; y ``very\_fast'' si la velocidad es mayor que 11.
    
    \item \textit{class\_w\_9}: Se dividen los datos de velocidad angular en 9 clases. Las clases son: ``radically\_left'' si la velocidad de rotación (w) es mayor o igual a 2; ``strongly\_left'' si w es menor que 2 y mayor o igual que 1; ``moderately\_left'' si w es menor que 1 y mayor o igual que 0.5; ``slightly\_left'' si w es menor que 0.5 y mayor o igual que 0.1; ``slight'' si w es menor que 0.1 y mayor a -0.1; ``slightly\_right'' si w es menor o igual que -0.1 y mayor que -0.5; ``moderately\_right''  si w es menor o igual que -0.5 y mayor que -1; ``strongly\_right'' si w es menor o igual que -1 y mayor a -2; y ``radically\_right'' si la velocidad de rotación es menor que -2.
\end{itemize}

Cuando se comenzó el proyecto se creó un conjunto de datos que constaba de 5006 pares de datos, de los cuales 2803 pares eran datos de entrenamiento, 701 eran datos de validación, y 1502 eran datos de \textit{test}. Este conjunto fue grabado gracias al piloto autónomo programado que conducía de forma autónoma únicamente por el circuito \textit{pistaSimple} en un mismo sentido. Este conjunto tenía un problema y es que el vehículo únicamente poseía datos de un circuito, por lo que no era capaz de generalizar y aprender a conducir en otros entornos.\\

Con el objetivo de analizar los datos de los que disponíamos se ha creado una gráfica de estadísticas (Figura \ref{fig.L1_L2_dataset1}) del conjunto de entrenamiento (círculos rojos) contra los datos de una conducción fallida en \textit{test} (cruces azules). En cada imagen se han analizado dos filas y se ha calculado el centroide de la línea roja del circuito para cada una de las filas (filas 350 y 260). En el eje \textit{x} de la gráfica, se representa el centroide de la fila 350 (L2), y el eje \textit{y} representa el centroide de la fila 260 (L1) de la imagen.\\


\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{figures/Infraestructura/L1_L2_dataset1_driving.png}
		\caption{Representación pares L1-L2 (\textit{Dataset1} contra conducción)}
		\label{fig.L1_L2_dataset1}
		\end{center}
\end{figure}

Se puede observar que hay bastantes casos conocidos para el coche, por ejemplo situaciones donde se encuentra en recta el coche. Pero también hay zonas de la gráfica donde se representan cruces azules (conducción fallida) y no hay ningún círculo rojo (conjunto de entrenamiento) alrededor. Esto quiere decir que el coche está ante situaciones desconocidas en las que no sabe qué hacer. \\

La gráfica \ref{fig.L1_L2_dataset1} nos hace pensar que es necesario entrenar el modelo con un conjunto de imágenes más representativo de las situaciones en las que el coche se puede encontrar. Por este motivo se creó un nuevo conjunto de datos. El nuevo conjunto de datos (denominado \textit{Dataset}) se ha grabado en tres circuitos diferentes: \textit{pistaSimple}, \textit{monacoLine}, \textit{nurburgrinLine}. El piloto programado ha dado varias vueltas a los 3 circuitos en ambos sentidos para grabar este conjunto. Este \textit{dataset} consta de 17341 pares de imágenes-acciones. Se han dividido los datos obteniendo 9710 pares de entrenamiento, 2428 pares de validación, y 5203 pares para \textit{test}.\\

La misma gráfica estadística que se ha empleado para evaluar el dataset inicial ``fallido'' se ha utilizado con el fin de evaluar el nuevo. En la Figura \ref{fig.L1_L2_dataset3} se puede ver cómo el nuevo conjunto de datos es muy representativo, ya que consigue abarcar la gran mayoría de los casos que eran desconocidos para el coche.\\

\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{figures/Infraestructura/L1_L2_Dataset3.png}
		\caption{Representación pares L1-L2 (nuevo \textit{Dataset} contra conducción)}
		\label{fig.L1_L2_dataset3}
		\end{center}
\end{figure}

En los circuitos utilizados para grabar el nuevo conjunto de datos existen más datos de rectas que de curvas, por este motivo se ha grabado también un \textit{dataset} \textit{complementario} al anterior de un circuito que solamente posee curvas (\textit{curveGP}). Este conjunto extendido  consta de 5268 pares de imágenes datos.\\

Este conjunto únicamente se ha añadido al entrenamiento de las redes neuronales recurrentes, ya que en las redes neuronales convolucionales ha sido suficiente con entrenar con el \textit{dataset} normal. En la Figura \ref{fig.L1_L2_dataset_curves} se puede ver la gráfica estadística de esta extensión del conjunto de datos (\textit{Dataset\_Curves}).\\

\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{figures/Infraestructura/L1_L2_Dataset_Curves.png}
		\caption{Representación pares L1-L2 (\textit{Dataset\_Curves} contra conducción)}
		\label{fig.L1_L2_dataset_curves}
		\end{center}
\end{figure}

La gráfica también se puede emplear para evaluar cómo se distribuyen los datos de las clases, tanto para la velocidad lineal (v) como para la velocidad de rotación (w). En la Figura \ref{fig.L1_L2_dataset_w} se representa el análisis de los pares L1-L2 (centroides de las filas 260 y 350) para 7 clases de w (``radically\_left'', ``moderately\_left'', ``slightly\_left'', ``slight'', ``slightly\_right'', ``moderately\_right'', ``radically\_right''). En la Figura \ref{fig.L1_L2_dataset_v} se representa el análisis de los pares L1-L2 para 5 clases de v (``negative'', ``slow'', ``moderate'', ``fast'', ``very\_fast''). En estas imágenes se observa cómo los ejemplos quedan más o menos agrupados por clases entorno a un rango de valores de L1 y L2. \\

\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{figures/Infraestructura/L1_L2_dataset3_w.png}
		\caption{Análisis de pares L1-L2 (\textit{Dataset}) para w}
		\label{fig.L1_L2_dataset_w}
		\end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{figures/Infraestructura/L1_L2_dataset3_v.png}
		\caption{Análisis de pares L1-L2 (\textit{Dataset}) para v}
		\label{fig.L1_L2_dataset_v}
		\end{center}
\end{figure}


En el entrenamiento de las redes neuronales convolucionales se ha empleado el conjunto de datos \textit{Dataset}; mientras que en el entrenamiento de las redes neuronales recurrentes se ha utilizado dicho conjunto, y adicionalmente el conjunto \textit{Dataset\_Curves}.\\

En ejecución, el piloto entrenado con las redes se ha probado en todos estos circuitos mencionados (\textit{pistaSimple}, \textit{monacoLine}, \textit{nurburgrinLine}, \textit{curveGP}) en la creación de los \textit{datasets}, y además se ha probado en el circuito \textit{pista\_simple} en ambos sentidos que las redes no han empleado para entrenamiento.


\section{Piloto autónomo basado en redes neuronales}

Se ha programado una aplicación de control visual con la infraestructura necesaria para cargar y emplear redes neuronales de conducción. Resuelve varias funcionalidades: (a) ofrece una interfaz gráfica al usuario que le ayuda a depurar el código; (b) ofrece acceso a sensores y actuadores en forma de métodos simples (oculta el \textit{middleware} de comunicaciones); (c) incluye código auxiliar para enviar a los motores las órdenes estimadas por las redes (bien de clasificación o de regresión). Lo deja todo atado para que el usuario sólo tenga que incluir su red y retoque un fichero donde se proporciona al vehículo las órdenes de velocidad predichas por la red. En la Figura \ref{fig.nodo_piloto} se puede observar la estructura que tiene esta aplicación.\\

\begin{figure}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{figures/Infraestructura/nodo_piloto.png}
		\caption{Estructura de la aplicación de control visual basada en redes neuronales}
		\label{fig.nodo_piloto}
		\end{center}
\end{figure}

Esta aplicación ofrece al programador un \acrfull{api} de sensores y actuadores, y de predicciones de la red. A cotinuación se puede observar el \acrshort{api} concreto de este proyecto:

\begin{itemize}
    \item \textit{camera.getImage}: Permite obtener la imagen de la cámara del coche.
    
    \item \textit{motors.sendV}: Para establecer la velocidad lineal.
    
    \item \textit{motors.sendW}: Para establecer la velocidad de giro.
    
    \item \textit{network.prediction\_v}: Para obtener la predicción de velocidad lineal de la red.
    
    \item \textit{network.prediction\_w}: Para obtener la predicción de velocidad de giro de la red.
\end{itemize}


En el archivo YML \footnote{YAML Ain't Markup Language format} se indican los puertos de los \textit{plugins} que emplea el coche de carreras. Además, tenemos que indicar el \textit{framework} de redes neuronales que emplearemos (Keras o Tensorflow), así como los pesos de modelos de redes neuronales que ya hemos entrenado y que cargaremos para poder predecir datos de velocidad. Este fichero (driver.yml) en el proyecto tiene el siguiente aspecto:\\


\vspace{10pt}
\begin{lstlisting}[basicstyle=\small]

Driver:

  CameraLeft:
    Server: 2 # 0 -> Deactivate, 1 -> Ice , 2 -> ROS
    Proxy: "cam_f1_left:tcp -h localhost -p 8995"
    Format: RGB8
    Topic: "/F1ROS/CameraL/image_raw"
    Name: FollowLineF1CameraLeft

  Motors:
    Server: 0 # 0 -> Deactivate, 1 -> Ice , 2 -> ROS
    Proxy: "Motors:tcp -h localhost -p 9999"
    Topic: "/F1ROS/Motors"
    Name: FollowLineF1Motors

  robot: F1

  Network:
    Framework: Keras  # Currently supported: "Keras" or "TensorFlow"
    Model_Classification_w: models/model_smaller_vgg_7classes_biased_cropped_w.h5
    Model_Classification_v: models/model_smaller_vgg_5classes_biased_cropped_v.h5
    Model_Regression_v: models/model_controlnet_v.h5
    Model_Regression_w: models/model_controlnet_w.h5
    Dataset: Net/Dataset
NodeName: Driver
\end{lstlisting}
\vspace{20pt}

Podemos ver que los motores emplean el Puerto 9999, mientras que la cámara emplea el Puerto 8995. Además, podemos observar que en este archivo se indica que se utilizará el \textit{framework} Keras, así como los modelos (para v y w) que cargaremos en el caso de emplear una red de clasificación o una red de regresión.\\

Se han creado dos clases que permiten cargar los modelos de v y w indicados en el archivo de configuración \textit{.yml}, así como predecir los valores de v y w, y almacenarlos en las variables \textit{self.network.prediction\_v} y \textit{self.network.prediction\_w}. La clase de Python creada para las redes neuronales de clasificación es ClassificationNetwork, y para redes de regresión es RegressionNetwork. En el archivo principal (driver.py) se indicará cuál de estas dos clases queremos emplear al ejecutar el nodo Piloto. De esta forma desde un fichero podremos emplear las velocidades predichas por la red e indicar las órdenes de velocidad al vehículo.\\

Se ha dividido la aplicación piloto en diferentes partes e hilos de ejecución para llevar a cabo diferentes tareas de forma simultánea. En este proyecto existen tres procesos diferenciados:

\begin{itemize}
    \item Hilo de percepción y control: Es el encargado de actualizar los datos de los sensores y los actuadores. El tiempo de refresco de este hilo es muy importante, y debe ser un periodo de tiempo muy corto, ya que se encarga de establecer la velocidad y la dirección del vehículo en todo momento. Si este intervalo de tiempo fuera muy grande, las decisiones que modifican la trayectoria del coche podrían ser incorrectas. Este hilo (\textit{ThreadPublisher}) se utiliza para actualizar los datos de la cámara y enviar órdenes a los motores. Se actualiza cada 80 milisegundos.
    
    \item Hilo de la interfaz gráfica de usuario (\acrshort{gui}): Se encarga de actualizar la \acrshort{gui}. El intervalo de actualización de este hilo es importante, ya que tenemos que mostrar la imagen que ve el coche en tiempo real. El intervalo de tiempo debe ser pequeño, se actualizará cada 50 ms.
    
    \item Hilo de la red neuronal: Es el encargado de inferir valores a partir de la última imagen recibida, de forma asíncrona. Cuando termina la inferencia, se almacena el valor dentro del elemento de red. Cuando el vehículo necesita los últimos datos de inferencia, solamente toma estos datos sin bloquear ningún proceso ni llamada. Este hilo (\textit{ThreadNetwork}) se debe actualizar en intervalos de tiempo pequeños para que el coche sea capaz de conducir. Se actualiza cada 50 ms.

\end{itemize}

En el proyecto es muy importante el tiempo de ejecución, ya que este tiempo influye en las decisiones que toma el vehículo, y cuanto más rápido sea el algoritmo mejor. En el tiempo que tarda en tomar decisiones el coche influirá el ordenador que empleemos. \\


\subsection{Interfaz gráfica}

La intergaz gráfica (\acrshort{gui}) del proyecto es una ayuda para proporcionar datos durante el pilotaje del vehículo. Esta interfaz se ha creado empleando PyQt5, dado que permite realizar interfaces con numerosos objetos gráficos (imágenes, botones, etc).\\

La \acrshort{gui} del proyecto (Figura \ref{fig.gui}) contiene la imagen que captura la cámara del vehículo. Esta imagen está situada en la parte superior izquierda de la \acrshort{gui}. Gracias a ella, el usuario puede tener una idea de la visión del coche y emplear estas imágenes como datos de entrada a las redes entrenadas.\\

En la parte derecha de la imagen mostrada en la \acrshort{gui} hay 4 leds que se corresponden con diferentes rangos de velocidades lineales; mientras que en la parte inferior hay 7 leds que se corresponden con velocidades angulares del coche. En función del valor predicho por la red se encenderá un led verde de la parte inferior y un led azul de la parte derecha. De esta forma, es más fácil obtener una visualización de las órdenes de velocidad aproximadas que está recibiendo el coche. \\

Además, para añadir más información de velocidad que le permita al usuario depurar fallos, a la derecha de los leds que indican la velocidad lineal se han añadido las órdenes de velocidades que se envían a los motores del coche. Por un lado, tenemos el valor de la velocidad lineal, que aparece indicado con una v; mientras que el valor de la velocidad angular se indica con una letra w.\\

Esta interfaz gráfica además muestra un teleoperador justo debajo del botón ``Play Code''. Mediante este teleoperador se puede mover manualmente el coche en el mundo de Gazebo si se desea. En la esquina superior derecha, donde se muestran las órdenes de velocidad del coche, aparecerán los valores de velocidad que tiene el mismo cuando se teledirige. La velocidad lineal del coche se puede controlar moviendo el \textit{joystick} en sentido vertical. La velocidad angular del vehículo se controla moviendo el \textit{joystick} en sentido horizontal.\\


\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/Infraestructura/gui.png}
		\caption{Interfaz gráfica (\acrshort{gui})}
		\label{fig.gui}
		\end{center}
\end{figure}


En la aplicación gráfica también hay cuatro botones importantes. El botón inferior  izquierdo, en el que aparece un símbolo de STOP, es el que emplearemos cuando teledirigimos el coche y queremos que pare en un punto y no siga navegando. El botón que se encuentra entre la imagen y el teleoperador, en el cual pone ``Play Code'', es el botón con el que le ordenamos al componente que comience a ejecutar el código del fichero donde le damos órdenes a los motores del coche. Este botón cambia de color al pulsarlo. Si queremos que este código pare en un determinado momento, pulsaremos el mismo botón haciendo que pare; y si queremos reanudar su comportamiento lo volveremos a pulsar.\\

Los otros dos botones se emplean para el manejo de un \textit{dataset}. Por un lado, tenemos el botón de la parte superior derecha, en el cual pone ``Save Dataset'', que sirve para crear un nuevo \textit{dataset} que guarde los datos tanto de velocidad como las imágenes que ve el coche durante la ejecución de su algoritmo. Este conjunto de datos se crea con la misma estructura que el conjunto de datos mencionado en la Sección \ref{dataset}, y se almacenará en el directorio ``Dataset''. Este conjunto de datos únicamente se crea si pulsamos este botón, de no ser así simplemente se ejecuta el algoritmo que permite navegar al vehículo. Por otra parte, el botón que se sitúa en la parte inferior derecha, permite borrar el \textit{dataset} creado.\\


